{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Pandas_logo.svg/1200px-Pandas_logo.svg.png>\n",
    "\n",
    "1. [Series](#series)\n",
    "2. [Dataframes](#dataframe)\n",
    "3. [Cargando archivos como Dataframes](#files)\n",
    "4. [Trabajando con filas y columnas](#rowxcolumns)\n",
    "    + 4.1 [Series y columnas de un dataframe](#cols)\n",
    "    + 4.2 [Selección de múltiples columnas](#columns)\n",
    "    + 4.3 [Selección de mútiples filas](#rows)\n",
    "    + 4.4 [Resumen función iloc](#iloc)\n",
    "    + 4.5 [Índices de un dataframe](#index)\n",
    "5. [Funciones sobre dataframes](#functions)\n",
    "6. [Agrupaciones sobre Dataframes](#groupy)\n",
    "7. [Merge de dataframes](#merge)\n",
    "8. [Nuevas columnas](#newcolumnas)\n",
    "9. [Borrado de filas y columnas](#drop)\n",
    "10. [Gestión de nulos](#dropna)\n",
    "\n",
    "Importamos la librería pandas para poder trabajar con DataFrames en Python, en caso de que no venga instalada por defecto podemos realizar lo siguiente:\n",
    "* <code>pip install pandas</code>\n",
    "* <code>conda install pandas</code>\n",
    "* <code>conda install -c anaconda pandas </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos pandas, utilizaremos el alias para denominar a cada función de pandas 'pd'\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series <a name=\"series\"></a> \n",
    "\n",
    "Se trata de una colección indexada que funciona de un modo similar a un diccionario de datos, es la unidad mínima con la que podemos trabajar en Pandas, de hecho, un Dataframe no es más que una sucesión de series.\n",
    "\n",
    "Debemos tener en cuenta que las series funcionan de forma similar a un diccionario de datos donde tenemos los archivos formados por {clave_1: 'valor uno', clave_2. 'valor dos', ....., clave_n: 'valor m'}. Las series pueden formarse a través de un numpy array o una lista y unos valores que actuarán como índices (si no se introducen se tomarán por defecto de 0 a la longitud del conjunto de elementos).\n",
    "\n",
    "Para crear una serie, simplemente utilizaremos la función <code>**Series**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bitcoin     15613.77\n",
       "Ethereum      496.29\n",
       "XRP             0.52\n",
       "Tether          0.83\n",
       "BTC Cash      242.03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criptos = pd.Series(\n",
    "    [15613.77, 496.29, 0.52, 0.83, 242.03], \n",
    "    index= ['Bitcoin', 'Ethereum', 'XRP', 'Tether', 'BTC Cash']\n",
    ")\n",
    "\n",
    "criptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las seires tienen su propio tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(criptos) # Clase Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bitcoin     15613.77\n",
       "Ethereum      496.29\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criptos[0: 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15613.77"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criptos['Bitcoin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta.\n",
    "\n",
    "Un objeto `pandas.Series` al ser similar a un diccionario de datos, ¿posee funciones similares a un diccionario de datos como `.keys()`o, `.values()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Bitcoin', 'Ethereum', 'XRP', 'Tether', 'BTC Cash'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criptos.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframes <a name=\"dataframe\"></a> \n",
    "\n",
    "La función principal que nos permite pasar prácticamente cualquier tipo de variable (lista, array, diccionario de datos...) es:\n",
    "* <code>__pandas.DataFrame()__</code>\n",
    "\n",
    "Veremos cómo crear DataFrames desde diferentes estructuras de datos.\n",
    "\n",
    "* A través de **Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Bitcoin</th>\n",
       "      <td>15613.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ethereum</th>\n",
       "      <td>496.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XRP</th>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tether</th>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BTC Cash</th>\n",
       "      <td>242.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "Bitcoin   15613.77\n",
       "Ethereum    496.29\n",
       "XRP           0.52\n",
       "Tether        0.83\n",
       "BTC Cash    242.03"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un Dataframe a través del objeto Series\n",
    "df_criptos = pd.DataFrame(criptos)\n",
    "\n",
    "# Vemos que por defecto, se genera una columna con nombre 0, \n",
    "# ya que no se lo hemos especificado.\n",
    "df_criptos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A través de **Numpy Array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.418544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.188623\n",
       "1  0.018089\n",
       "2  0.991158\n",
       "3  0.418544\n",
       "4  0.004762"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo 2 a través numpy array\n",
    "import numpy as np\n",
    "\n",
    "# Creamos un array de 5 número aleatorios\n",
    "array_uno = np.random.rand(5)\n",
    "\n",
    "pd.DataFrame(array_uno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importante destacar en el ejemplo anterior, que al no utilizar ningún parámetro como índice, automáticamente ha tomado valores de 0 a n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A través de **Listas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hola mundo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adios</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0  hola mundo\n",
       "1           1\n",
       "2        3.14\n",
       "3       adios"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo 3 listas\n",
    "\n",
    "# Creamos una lista\n",
    "lista = ['hola mundo', 1, 3.14, 'adios']\n",
    "\n",
    "# Pasamos la lista a un DataFrame\n",
    "df_list = pd.DataFrame(lista)\n",
    "\n",
    "df_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A través de un **diccionario de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID001': 'Cliente uno',\n",
       " 'ID002': 'Cliente dos',\n",
       " 'ID003': 'Cliente tres',\n",
       " 'ID004': 'Cliente cuatro',\n",
       " 'ID005': 'Cliente cinco'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo 4 Diccionario de datos\n",
    "\n",
    "# Creamos un Diccionario de datos\n",
    "dict_cli = {'ID001': 'Cliente uno',\n",
    "            'ID002': 'Cliente dos',\n",
    "            'ID003': 'Cliente tres',\n",
    "            'ID004': 'Cliente cuatro',\n",
    "            'ID005': 'Cliente cinco'}\n",
    "\n",
    "dict_cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID001</th>\n",
       "      <td>Cliente uno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID002</th>\n",
       "      <td>Cliente dos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID003</th>\n",
       "      <td>Cliente tres</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID004</th>\n",
       "      <td>Cliente cuatro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID005</th>\n",
       "      <td>Cliente cinco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0\n",
       "ID001     Cliente uno\n",
       "ID002     Cliente dos\n",
       "ID003    Cliente tres\n",
       "ID004  Cliente cuatro\n",
       "ID005   Cliente cinco"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasamos el dict a un DataFrame\n",
    "\n",
    "df_dict = pd.DataFrame.from_dict(dict_cli, orient='index')\n",
    "\n",
    "df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que cuando se trata de un diccionario de datos, tenemos que utilizar el parámetro **orient** para que reconozca correctamente el campo clave como índice. De lo contrario, podemos utilizar el parámetro **index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 1\n",
    "\n",
    "Tomando la siguiente lista como referencia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "calificaciones = [\n",
    "    ('Alberto', 4),\n",
    "    ('Noelia', 7.25),\n",
    "    ('Marcos', 9),\n",
    "    ('Guillermo', 5.25)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea un dataframe a través de la lista.\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alberto</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Noelia</td>\n",
       "      <td>7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marcos</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Guillermo</td>\n",
       "      <td>5.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1\n",
       "0    Alberto  4.00\n",
       "1     Noelia  7.25\n",
       "2     Marcos  9.00\n",
       "3  Guillermo  5.25"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En clase\n",
    "pd.DataFrame(calificaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargando archivos como Dataframes <a name=\"files\"></a> \n",
    "\n",
    "Una de las grandes ventajas que supone trabajar con DataFrames es que podemos cargar archivos muy fácilmente y poder procesar sus filas y columnas. Hay varios tipos de datos que podemos cargar a pandas:\n",
    "\n",
    "* CSV\n",
    "* JSON\n",
    "* HTML\n",
    "* EXCEL\n",
    "* HDF5\n",
    "* TXT\n",
    "* ORC\n",
    "* STATA\n",
    "* ...\n",
    "\n",
    "Todos los tipos de datos que podemos cargar se encuentran en el siguiente link: https://pandas.pydata.org/docs/user_guide/io.html#io\n",
    "\n",
    "A lo largo del contenido mostraremos las principales funcionalidades de los dataframes desde csv como dataframe.\n",
    "\n",
    "Para cargar un csv como un Dataframe disponemos de la función </code>**read_csv**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/Cristian Mendieta/OneDrive/Escritorio/Data Science/Pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m houses \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/Cristian Mendieta/OneDrive/Escritorio/Data Science/Pandas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/Cristian Mendieta/OneDrive/Escritorio/Data Science/Pandas'"
     ]
    }
   ],
   "source": [
    "houses = pd.read_csv('C:/Users/Cristian Mendieta/OneDrive/Escritorio/Data Science/Pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'houses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m houses\n",
      "\u001b[1;31mNameError\u001b[0m: name 'houses' is not defined"
     ]
    }
   ],
   "source": [
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 2\n",
    "\n",
    "Lee el archivo 'compras_uno.csv' como dataframe\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 3\n",
    "\n",
    "Lee el archivo 'compras_dos.csv' como dataframe\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 4\n",
    "\n",
    "Lee el archivo 'compras_tres.csv' como dataframe\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 5\n",
    "\n",
    "Lee de nuevo el archivo 'housing_California.csv' como dataframe, utiliza el parámetro `header=None`\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 6\n",
    "\n",
    "Lee de nuevo el archivo 'housing_California.csv' como dataframe, utiliza el parámetro `header=[0,1,2]`\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio 7\n",
    "\n",
    "\n",
    "Carga el dataset 'housing_California.csv', cargando solamente las columnas housing_median_age y population\n",
    "\n",
    "#### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ej_7 = pd.read_csv('housing_California.csv', usecols=['housing_median_age', 'population'])\n",
    "\n",
    "ej_7 # Con usecols podemos definir las columnas que necesitemos cargar en el momento de lectura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajando con filas y columnas de un dataframe <a name=\"rowsxcolumns\"></a> \n",
    "\n",
    "### Series y Columnas de un dataframe. <a name=\"cols\"></a> \n",
    "\n",
    "Tal y como hemos visto antes un dataframe es una sucesión o colección de series, es decir, que cada columna actúa como una serie ya que todas las columnas comparten el mismo índice. \n",
    "\n",
    "Para acceder a una columna tenemos que escribir entre corchetes el nombre de la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses['housing_median_age']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si atendemos al tipo de clase que tiene una columna veremos que es Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(houses['housing_median_age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otra forma de acceder a las columnas de un dataframe es:\n",
    "\n",
    "* nombre_df.__nombre_columna__ (sin las comillas de string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.housing_median_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de múltiples columnas <a name=\"columns\"></a> \n",
    "\n",
    "Ahora que ya hemos visto como un DataFrame se compone de Series, podemos ver cómo seleccionar varias columnas. Para ello, simplemente tenemos que encerrar entre corchetes los nombres de las columnas que queremos seleccionar como:\n",
    "\n",
    "__nombre_df[['columna_uno', 'columna_dos', 'columna_tres']]__\n",
    "\n",
    "Análogamente, podremos pasar una lista con nombres de las columnas.\n",
    "\n",
    "Para realizar lo mismo mediante indexación, es decir, obtener un subconjunto de columnas del dataframe por la posición que ocupan las columnas podemos hacer:\n",
    "* __nombre_dataframe[nombre_dataframe.columns[[col_n, col_m]]]__\n",
    "* __nombre_dataframe.iloc[:, [col_n, col_m]]__\n",
    "\n",
    "Mediante nombres de columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[['housing_median_age', 'total_bedrooms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['housing_median_age', 'total_bedrooms', 'population']\n",
    "houses[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mediante índices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.columns[0: 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[houses.columns[2:6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar varias columnas con iloc, tenemos que tener en cuenta que un dataframe se distribuye de la siguiente manera.\n",
    "\n",
    "* __dataframe[filas, columnas]__: En donde tanto filas como columnas son indexables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.iloc[:,[1,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# houses.iloc[:,['latitude', 'total_rooms']] # Solo funciona con números"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de múltiples filas de un dataframe <a name=\"rows\"></a> \n",
    "\n",
    "Por lo general, podemos utilizar las mismas propiedades que las de las listas, salvo seleccionar una única fila que es diferente:\n",
    "* Para seleccionar desde la primera fila hasta un límite realizamos: <code>__dataframe[0:n]__</code>, análogamente podemos omitir el cero y realizar simplemente: <code>__dataframe[ :n]__</code>\n",
    "* Para seleccionar desde una fila hasta el final realizamos: <code>__dataframe[n:]__</code>\n",
    "* Para seleccionar un rango definido de filas realizamos: <code>__dataframe[n:m]__</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos de la fila 0 a la 2\n",
    "houses[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que es lo mismo si quitamos el cero.\n",
    "houses[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos de fila n al final\n",
    "houses[20635:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rango personalizado, escogemos de fila 150 a 200\n",
    "houses[150:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para seleccionar una sola fila no podemos hacer la misma operación que en las listas, indexar una única posición <code>lista[n]</code>, ya que esto no nos devuelve nada, para ello, tenemos que seleccionar como un rango personalizado la fila que queremos mostrar más una posición <code>dataframe[n:n+1]</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[1000:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[1000:1001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen función iloc <a name=\"iloc\"></a> \n",
    "\n",
    "Con la función __.iloc__ podemos seleccionar varias filas de una forma muy sencilla que puede resumirse como:\n",
    "* <code>dataframe.iloc[0]</code> - Primera fila de un dataframe.\n",
    "* <code>dataframe.iloc[1]</code> - Segunda fila de un dataframe.\n",
    "* <code>dataframe.iloc[-1]</code> - (Indexación negativa) Última fila de un dataframe\n",
    "* <code>dataframe.iloc[[n]]</code> - Fila _n_ del dataframe.\n",
    "* <code>dataframe.iloc[n:m]</code> - Rango personalizado de las filas _n_ a _m_\n",
    "\n",
    "En columnas el resumen de la función __.iloc__ pasaría a ser:\n",
    "* <code>dataframe.iloc[:, 0]</code> - Primera columna de un dataframe.\n",
    "* <code>dataframe.iloc[:, 1]</code> - Segunda columna de un dataframe.\n",
    "* <code>dataframe.iloc[-1]</code> - (Indexación negativa) Última columna de un dataframe\n",
    "* <code>dataframe.iloc[:,[n,m]]</code> - Exactamente, las columnas _n_ y _m_ de un dataframe.\n",
    "* <code>dataframe.iloc[:, n:m]</code> - Rango personalizado de las columnas _n_ a _m_ de un dataframe.\n",
    "\n",
    "Podemos también realizar una selección múltiple de columnas filas con __.iloc__ con los siguientes ejemplos:\n",
    "* <code>dataframe.iloc[[0,5,7,9], [1,4]]</code> - Selección de las filas 0,5,7,9 de las columnas 1 y 4\n",
    "* <code>dataframe.iloc[0:10, 0:2]</code> - Selección basada en rangos de las filas 0 a 10 de las columnas 0 a 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.iloc[[20,5680,19875], [3, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.iloc[0:10, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Índices de un DataFrame <a name=\"index\"></a> \n",
    "\n",
    "Se tratan de las posiciones que ocupa cada fila dentro de un dataframe, a no ser que se especifique un tipo de índice concreto basado en etiquetas, los índices serán de 0 a la longitud total del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un dataframe\n",
    "ventas = {\n",
    "   'region': [\"EUROPA\", \"EUROPA\", \"EUROPA\", \n",
    "              \"USA\", \"USA\", \"USA\", \"LATAM\", \"LATAM\"],\n",
    "   'ventas':[153752, 168742, 162587, 256198, 285743, 290371, 145638, 151678],\n",
    "   'anio':[2018, 2019, 2020, 2018, 2019, 2020, 2018, 2019]\n",
    "}\n",
    "df = pd.DataFrame(ventas)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para observar el índice de un dataframe podemos hacer uso de su atributo <code>**index**</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dependiendo de cómo estén formados nuestros datos, vamos a poder crear multi índices basados en columnas propias de nuestro dataframe, si nos fijamos la columna region y anio tienen elementos repetidos. Esto nos permitirá hacer multi-índices donde tengamos un continente por año de ventas.\n",
    "\n",
    "Con la función <code> set_index()</code> vamos a poder establecer un nuevo índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_year = df.set_index([\"region\", \"anio\"])\n",
    "region_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vista del nuevo dataframe, podemos ver que ahora las columnas region y anio actúan como índice, por lo que si consultamos la primera fila..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_year.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el dato que pertenece al volumen de ventas, siendo region (Europe) y el año (2018) sus índices\n",
    "\n",
    "Del mismo modo, podemos pasar una lista como índice a un dataframe. Obviamente, esta lista debe ser de la misma longitud que el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = ['REGISTRO_1', 'REGISTRO_2', 'REGISTRO_3', 'REGISTRO_4', \n",
    "          'REGISTRO_5', 'REGISTRO_6', 'REGISTRO_7', 'REGISTRO_8']\n",
    "\n",
    "df.index = indice\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la función <code>.loc</code> podemos buscar elementos en el índice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['REGISTRO_6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones sobre dataframes <a name=\"functions\"></a> \n",
    "\n",
    "A continuación, vamos a ver un listado de algunas de las principales funciones que podemos aplicar en un dataframe para operar en sus columnas:\n",
    "\n",
    "* Obtener las primeras filas de un dataframe con __<code>.head</code>__\n",
    "* Obtener las últimas filas de un dataframe con __<code>.tail</code>__\n",
    "* Obtener los elmentos únicos de una columna de un dataframe con __<code>.unique</code>__\n",
    "* Obtener la frecuencia de los valores únicos de una columna de un dataframe __<code>.value_counts</code>__\n",
    "* Obtener un resumen estadístico del dataset con __<code>.describe</code>__\n",
    "* Obtener la media de una columna con __<code>.mean</code>__\n",
    "* Obtener una copia de un dataframe con __<code>.copy</code>__\n",
    "* Ver los nombres de las columnas de un dataframe con __<code>.columns</code>__\n",
    "* Obtener la correlación entre todas las variables numéricas con __<code>.corr</code>__\n",
    "* Borrar duplicados de un dataframe con __<code>.drop_duplicates</code>__\n",
    "* Especialmente para Big Data sets podemos ver el consumo en memoria RAM de nuestro dataset con __<code>.memory_usage</code>__\n",
    "* Ver un resumen resumen gráfico (basado en densidad, scatter plots y gráficas de correlaciones) de todas las variables del dataframe con __<code>.scatter_matrix</code>__\n",
    "* Obtener un histograma de cada variable numérica del dataset con __<code>.hist</code>__\n",
    "* Obtener el esquema de los datos con __`info`__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeras filas de un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeras filas del dataframe\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si en .head() no especificamos nada, por defecto, se muestran 5, podemos especificar el número de filas a mostrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Últimas filas de un Dataframe\n",
    "\n",
    "Lo mismo pasa con el comando __tail__, si no le pasamos como parámetro el número de filas a visualizar, tomará las últimas 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores únicos por columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos los valores únicos de la columna \n",
    "houses['ocean_proximity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses['latitude'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos comprobar esta es una función que tiene un mayor impacto en variables categóricas, ya por lo general, las variables numéricas tienen demasiados valores diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen estadístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumen estadístico.\n",
    "houses.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es interesante observar que el resumen estadístico descarta automáticamente cualquier variable que no sea numérica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Media de una columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Media de la variable total rooms', round(houses['total_rooms'].mean(), 3))\n",
    "print('Media de la variable total bedrooms', round(houses['total_bedrooms'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copia de un dataframe\n",
    "\n",
    "Al igual que en listas y arrays los dataframes comparten memoria. Es fácil equivocarnos y asignar a una nueva variable un dataframe completo, posteriormente, en esta nueva variable realizar modificaciones, pensando que sólamente las estamos realizando en la copia del dataframe, pero no es así, estamos realizando modificaciones en ambos dataframes ya que al estar almacenados en memoria, comparten las mismas posiciones, veamos un ejemplo de como NO copiar un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_copy = houses\n",
    "\n",
    "# Modificamos la primera fila por ceros\n",
    "bad_copy.iloc[[0]] = np.zeros(len(houses.columns))\n",
    "\n",
    "bad_copy.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que los cambios se reflejan en el dataframe original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, hemos modificado ambos dataframes, para únicamente realizar modificaciones sobre la copia, hemos de hacer uso del comando <code>.copy</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv('housing_California.csv')\n",
    "\n",
    "# Copiamos correctamente el dataframe\n",
    "df_copia = houses.copy()\n",
    "\n",
    "df_copia.iloc[[0]] = np.zeros(len(houses.columns))\n",
    "\n",
    "df_copia.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlaciones de las variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nótese que automáticamente toma todas las variables numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombres de las columnas de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.columns[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas de un dataframe pueden trabajarse como listas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Borrar duplicados de un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para verlo más claro, vamos a realizar una copia de las diez primeras posiciones del data frame\n",
    "ten_rows = houses.head(10).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicamos la fila 9 varias veces\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])\n",
    "ten_rows = ten_rows.append(ten_rows.iloc[[9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_rows = ten_rows.drop_duplicates(inplace = False, keep = 'first')\n",
    "ten_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uso de RAM para un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumo RAM del dataframe en BYTES\n",
    "houses.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis gráfico con scatter matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración para mostrar gráficas en notebook\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Importamos scatter_matrix\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# Es necesario que configuremos el tamaño de las gráficas que será el mismo que el número de columnas\n",
    "scatter_matrix(houses, figsize = (len(houses.columns), \n",
    "                                  len(houses.columns)), \n",
    "               diagonal = 'kde');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogramas de las variables numéricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramas de cada variable continua del dataframe.\n",
    "houses.hist(figsize = (len(houses.columns), len(houses.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiando el tipo de las variables.\n",
    "\n",
    "Con la función `info` podemos obtener la información del tipo de variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos comprobar, todas las variables son de tipo float, excepto ocean_proximity que es de tipo object, cuando la realidad es que esto, no es así, algunas de las transformaciones más importantes que podemos realizar en un dataframe sobre sus variables es cambiarles el tipo, es decir que pasen a ser categóricas o tipo fecha, vamos a ver cómo cambiar a tipo categórica las variables de un dataframe.\n",
    "\n",
    "Una de las posibles formas de cambiar el tipo de una variable es a través de `pd.Categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses[\"ocean_proximity\"] = pd.Categorical(houses[\"ocean_proximity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos la información del dataframe de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, podemos mostrar un resumen estadístico solamente de las variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.describe(include='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AGRUPACIÓN DE DATAFRAMES - GROUP BY <a name=\"groupby\"></a> \n",
    "\n",
    "Al igual que en SQL, desde Python también podemos realizar agrupaciones de nuestros datos con la función __<code>groupby</code>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos por la media de los valores numéricos para la columna ocean_proximity\n",
    "houses.groupby(['ocean_proximity']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos cuántos tipos el total de dormitorios en función de\n",
    "# su frecuencia.\n",
    "houses.groupby(['total_bedrooms']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.groupby(['total_bedrooms']).count()['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener el porcentaje de valores para una variable categórica\n",
    "print((pd.crosstab(index=houses[\"ocean_proximity\"], columns=\"count\"))/len(houses) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MERGE DE DATAFRAMES <a name=\"merge\"></a> \n",
    "\n",
    "En algunas ocasiones, vamos a necesitar unir dos o más datasets para ello, en primer lugar, al igual que con listas, podemos hacer uso de la función __<code>.append</code>__\n",
    "\n",
    "Debido a la dimensión de filas y columnas del dataframe, vamos a crear dos dataframes más reducidos para poder ejemplificar correctamente la función append."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos datasets reducidos\n",
    "first_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms']].head(5).copy()\n",
    "\n",
    "\n",
    "last_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms']].tail(4).copy()\n",
    "\n",
    "print(first_positions.shape)\n",
    "print(last_positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambos datasets con append\n",
    "first_positions = first_positions.append(last_positions)\n",
    "\n",
    "print(first_positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante que tengamos en cuenta con la presencia de nuevas columnas que aparezcan solamente en uno de los dataframes que vayamos a concatenar. Para ejemplificarlo, vamos a obtener de nuevo los datasets, dando una columna a más al dataset con las últimas posiciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos datasets reducidos\n",
    "first_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms']].head(5).copy()\n",
    "\n",
    "\n",
    "last_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms',\n",
    "                             'households']].tail(4).copy()\n",
    "\n",
    "print(first_positions.shape)\n",
    "print(last_positions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos ambos datasets con append\n",
    "first_positions = first_positions.append(last_positions)\n",
    "\n",
    "first_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En segundo lugar, podemos hacer uso de la función __<code>.concat</code>__. Es muy importante saber los tipos de unión ( _join_ ) que podemos realizar al concatenar datasets\n",
    "* __inner__: Se realiza la unión por los elementos comunes de ambos datasets.\n",
    "* __outer__: La unión se realiza por todos los elementos entre los datasets\n",
    "    \n",
    "Se recomienda echar un vistazo a la documentación para ver los diferentes tipos de join que podemos realizar. https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms',\n",
    "                             'ocean_proximity']].head(5).copy()\n",
    "\n",
    "\n",
    "last_positions = houses[['housing_median_age', \n",
    "                             'total_rooms', \n",
    "                             'total_bedrooms',\n",
    "                             'households',\n",
    "                             'ocean_proximity']].tail(4).copy()\n",
    "\n",
    "union_outer = pd.concat([first_positions, last_positions], \n",
    "                        ignore_index=True, join='outer')\n",
    "\n",
    "union_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner = pd.concat([first_positions, last_positions], \n",
    "                        ignore_index=True, join='inner')\n",
    "\n",
    "union_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compo podemos ver en el merge por tipo _inner_ la columna _households_ del nuevo dataset no aparece ya que no es un elemento común entre ambos datasets. No obstante hemos de tener en cuenta que si un dataset no tiene filas pertenecientes a una columna de otro dataset como es el caso de la columna _households_ que únicamente aparece en el nuevo dataset. Sus valores, pasarán a ser nulos.\n",
    "\n",
    "## NUEVAS COLUMNAS <a name=\"newcolumnas\"></a> \n",
    "\n",
    "En muchas ocasiones, vamos a necesitar añadir nuevas columnas a un dataframe o realizar modificaciones entre las columnas de un dataframe para obtener una nueva. Es importante saber que las operaciones se realizan de forma columnar, es decir, si dos columnas tienen una misma longitud podemos realizar una operación entre ambas si necesidad de iterara sobre sus filas.\n",
    "\n",
    "Para agregar una nueva columna simplemente podemos crear una nueva variable con el nombre del dataframe y el nombre de la columna que vamos a crear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(65, 120, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner['area'] = np.random.randint(65, 120, len(union_inner))\n",
    "\n",
    "print(union_inner.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos crear una nueva columna que sea la media de camas por habitaciones totales\n",
    "\n",
    "union_inner['mean_bedrooms'] = round(union_inner['total_rooms'] / union_inner['total_bedrooms'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BORRADO DE FILAS Y COLUMNAS <a name=\"drop\"></a> \n",
    "\n",
    "En algunas ocasiones, cuando realicemos limpieza de datos o, porque no sean objeto de nuestro análisis vamos a necesitar borrar filas o columnas de un dataframe, para ambos casos la función es la misma __<code>.drop</code>__, si el borrado queremos realizarlo para filas usaremos en el parámetro __axis__ el valor 0 y para las columnas el valor 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_inner = union_inner.drop(['housing_median_age', 'mean_bedrooms'], axis = 1)\n",
    "\n",
    "union_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrado por filas\n",
    "print('TODAS LAS FILAS')\n",
    "print(union_inner, \"\\n\")\n",
    "\n",
    "union_inner = union_inner.drop(3, axis=0)\n",
    "\n",
    "print('BORRADO DE FILA 3')\n",
    "print(union_inner.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GESTIÓN DE NULOS <a name=\"dropna\"></a> \n",
    "\n",
    "Finalmente, como es habitual cuando trabajamos con dataframes pueden aparecer los _missing values_ o simplemente, valores nulos, en Python representados por el string __NaN__, mediante la función __<code>.isnull</code>__ podremos saber si un elemento de un dataframe es nulo o no, una práctica muy habitual es obtener el número de valores nulos por columna en un dataframe y su porcentaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*CANTIDAD de datos nulos por columna en el dataframe\")\n",
    "print(union_outer.isnull().sum())\n",
    "print(\"----------------------------------\")\n",
    "print(\"*PORCENTAJE de datos nulos por columna en el dataframe\")\n",
    "print(union_outer.isnull().sum()/len(union_outer)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si lo que queremos es reemplazar los valores nulos y no borrarlos haremos uso de la función __<code>.fillna</code>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer['households'] = union_outer['households'].fillna(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*CANTIDAD de datos nulos por columna en el data frame\")\n",
    "print(union_outer.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por el contrario, si lo que queremos es borrar los valores nulos de un dataframe podemos hacer uso de la función __<code>.dropna</code>__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer = pd.concat([first_positions, last_positions], \n",
    "                        ignore_index=True, join='outer', sort=False)\n",
    "\n",
    "union_outer = union_outer.dropna()\n",
    "\n",
    "print(\"*CANTIDAD de datos nulos por columna en el data frame\")\n",
    "print(union_outer.isnull().sum())\n",
    "\n",
    "print(union_outer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escribiendo dataframe como csv\n",
    "\n",
    "Al igual que podemos cargar datos de diferentes fuentes de datos y procesarlos como un dataframe, también podemos posteriormente escribir un dataframe en una de las múltiples fuentes que acepta pandas para exportar archivos, en esta ocasión, volcaremos la información de un dataframe como un .csv, para ello, disponemos de la función <code>**to_csv**</code>. Como parámetros utilizaremos, el nombre del archivo, el argumento __sep__ para utilizar un tipo de separador u otro y, si no queremos que se muestre el índice del dataframe, utilizaremos el argumento __index__ con valor _none_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_outer.to_csv('RESULTADOS.csv', sep=',', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
